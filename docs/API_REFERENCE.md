# Med3D-LISA API å¿«é€Ÿå‚è€ƒ

## ğŸ¯ æ ¸å¿ƒ API

### 1. æ¨¡å‹åˆå§‹åŒ–

```python
from model.meta_arch.med3d_lisa import Med3DLISA_Full, Med3DLISAConfig

# åˆ›å»ºé…ç½®
config = Med3DLISAConfig(
    # LLM åŸºç¡€é…ç½®
    hidden_size=4096,
    num_experts=8,
    num_experts_per_tok=2,
    
    # Stage 1: Alignment
    biobert_model='dmis-lab/biobert-v1.1',
    biobert_freeze_layers=8,
    latent_dim=512,
    alignment_temperature=0.07,
    
    # Stage 2: RAG
    rag_top_k=3,
    rag_num_entries=1000,
    rag_injection_position='prepend',
    
    # Stage 4: Self-Correction
    consistency_threshold=0.7,
    max_correction_iterations=3,
    
    # Loss weights
    lambda_alignment=0.1,
    lambda_dice=1.0,
    lambda_matching=0.5
)

# åˆå§‹åŒ–æ¨¡å‹
model = Med3DLISA_Full(config)
```

---

### 2. è®­ç»ƒ (Training)

```python
# å‡†å¤‡æ•°æ®
batch = {
    'input_ids': torch.LongTensor,      # [B, L] - æŒ‡ä»¤æ–‡æœ¬
    'attention_mask': torch.Tensor,     # [B, L]
    'images': torch.FloatTensor,        # [B, 1, D, H, W] - CT volume
    'clinical_reports': {
        'input_ids': torch.LongTensor,  # [B, L_text] - ä¸´åºŠæŠ¥å‘Š
        'attention_mask': torch.Tensor  # [B, L_text]
    },
    'labels': torch.LongTensor,         # [B, L] - ç›®æ ‡æŠ¥å‘Š
    'masks_gt': torch.FloatTensor       # [B, 1, D, H, W] - Ground truth mask
}

# å‰å‘ä¼ æ’­
outputs = model(
    input_ids=batch['input_ids'],
    attention_mask=batch['attention_mask'],
    images=batch['images'],
    clinical_reports=batch['clinical_reports'],
    labels=batch['labels'],
    masks_gt=batch['masks_gt'],
    output_hidden_states=True,
    return_dict=True
)

# è·å–æŸå¤±å’Œè¾“å‡º
total_loss = outputs['loss']              # æ€»æŸå¤±
lm_loss = outputs['lm_loss']              # è¯­è¨€æ¨¡å‹æŸå¤±
seg_loss = outputs['seg_loss']            # åˆ†å‰²æŸå¤±
alignment_loss = outputs['alignment_loss'] # å¯¹é½æŸå¤±
matching_loss = outputs['matching_loss']   # åŒ¹é…æŸå¤±
pred_masks = outputs['pred_masks']        # é¢„æµ‹æ©ç  [B, 1, D, H, W]

# åå‘ä¼ æ’­
total_loss.backward()
optimizer.step()
```

**æŸå¤±è®¡ç®—å…¬å¼**:
```
total_loss = lm_loss + Î»_dice * seg_loss + Î»_align * alignment_loss + Î»_match * matching_loss
```

---

### 3. æ¨ç† (Inference)

#### åŸºç¡€æ¨ç†ï¼ˆæ— è‡ªæˆ‘ä¿®æ­£ï¼‰
```python
generated_ids, pred_masks, info = model.generate_with_mask(
    input_ids=prompt_ids,           # [1, L] - ç”¨æˆ·æŒ‡ä»¤
    images=ct_volume,               # [1, 1, D, H, W]
    clinical_reports=reports,       # Dict (å¯é€‰)
    max_new_tokens=512,
    enable_self_correction=False    # å…³é—­è‡ªæˆ‘ä¿®æ­£
)

# è§£ç æ–‡æœ¬
report = tokenizer.decode(generated_ids[0])
```

#### å¸¦è‡ªæˆ‘ä¿®æ­£çš„æ¨ç†ï¼ˆæ¨èï¼‰
```python
generated_ids, pred_masks, correction_info = model.generate_with_mask(
    input_ids=prompt_ids,
    images=ct_volume,
    clinical_reports=reports,
    max_new_tokens=512,
    enable_self_correction=True,    # å¯ç”¨è‡ªæˆ‘ä¿®æ­£
    temperature=0.7,
    top_p=0.9
)

# æ£€æŸ¥ä¿®æ­£æ•ˆæœ
print(f"è¿­ä»£æ¬¡æ•°: {correction_info['num_iterations']}")
print(f"æœ€ç»ˆåˆ†æ•°: {correction_info['final_score']:.3f}")
print(f"æ˜¯å¦æ”¹è¿›: {correction_info['improved']}")

# æŸ¥çœ‹å†å²
for i, result in enumerate(correction_info['history']):
    print(f"Iteration {i}: score = {result['consistency_score']:.3f}")
```

---

### 4. RAG çŸ¥è¯†åº“ç®¡ç†

#### åŠ è½½é¢„æ„å»ºçŸ¥è¯†åº“
```python
# è®¿é—® RAG retriever
rag_retriever = model.model.rag_retriever

# åŠ è½½çŸ¥è¯†åº“
rag_retriever.load_knowledge_base('path/to/knowledge_base.pt')
```

#### æ„å»ºæ–°çŸ¥è¯†åº“
```python
import torch
from model.encoders.biobert_encoder import BioBERTEncoder

# 1. å‡†å¤‡åŒ»å­¦çŸ¥è¯†æ–‡æœ¬
medical_texts = [
    "Pulmonary nodules are small masses in the lung...",
    "Ground glass opacity indicates...",
    # ... æ›´å¤šåŒ»å­¦çŸ¥è¯†
]

# 2. ç¼–ç çŸ¥è¯†
biobert = BioBERTEncoder()
knowledge_embeddings = []

for text in medical_texts:
    tokenized = biobert.tokenizer(
        text, 
        return_tensors='pt', 
        padding=True, 
        truncation=True
    )
    embed = biobert(tokenized['input_ids'], tokenized['attention_mask'])
    knowledge_embeddings.append(embed)

# 3. ä¿å­˜çŸ¥è¯†åº“
knowledge_base = torch.stack(knowledge_embeddings)
rag_retriever.knowledge_base.data = knowledge_base
rag_retriever.save_knowledge_base('path/to/knowledge_base.pt')
```

---

### 5. ç»„ä»¶ç‹¬ç«‹ä½¿ç”¨

#### BioBERT Encoder
```python
from model.encoders.biobert_encoder import BioBERTEncoder

encoder = BioBERTEncoder(
    model_name='dmis-lab/biobert-v1.1',
    freeze_layers=8
)

# ç¼–ç æ–‡æœ¬
text_embeds = encoder(
    input_ids=tokenized['input_ids'],
    attention_mask=tokenized['attention_mask']
)  # [B, 768]
```

#### Unified Alignment
```python
from model.encoders.uni_alignment import UnifiedAlignmentModule

alignment = UnifiedAlignmentModule(
    image_dim=512,
    text_dim=768,
    latent_dim=512
)

# å¯¹é½å›¾åƒå’Œæ–‡æœ¬
outputs = alignment(
    image_features,  # [B, 512]
    text_features,   # [B, 768]
    return_loss=True
)

aligned_image = outputs['image_embeds']    # [B, 512]
aligned_text = outputs['text_embeds']      # [B, 512]
loss = outputs['contrastive_loss']         # Scalar
```

#### Consistency Checker
```python
from model.correction.consistency import ConsistencyChecker

checker = ConsistencyChecker(
    mask_channels=256,
    text_hidden_size=4096,
    embed_dim=512
)

# æ£€æŸ¥ä¸€è‡´æ€§
outputs = checker(
    mask_output=predicted_mask,    # [B, 1, D, H, W]
    text_embeds=hidden_states,     # [B, L, 4096]
    return_attention=True
)

score = outputs['consistency_score']      # [B, 1] âˆˆ [0, 1]
attention = outputs['attention_weights']  # [B, 1, L]
```

---

## ğŸ“‹ æ•°æ®æ ¼å¼è§„èŒƒ

### è¾“å…¥æ ¼å¼

#### 1. CT Volume (images)
```python
Shape: [B, 1, D, H, W]
dtype: torch.float32
Range: [0, 1] (normalized)
Example: [2, 1, 96, 256, 256]
```

#### 2. Clinical Report (clinical_reports)
```python
{
    'input_ids': torch.LongTensor,      # [B, L_text]
    'attention_mask': torch.Tensor      # [B, L_text]
}
# ä½¿ç”¨ BioBERT tokenizer
```

#### 3. User Instruction (input_ids)
```python
Shape: [B, L]
dtype: torch.int64
Example prompt: "Please segment the lung nodule and generate a report. <SEG>"
# æ³¨æ„: å¿…é¡»åŒ…å« <SEG> token æ‰ä¼šç”Ÿæˆåˆ†å‰²æ©ç 
```

#### 4. Ground Truth Mask (masks_gt)
```python
Shape: [B, 1, D, H, W]
dtype: torch.float32
Range: {0, 1} (binary mask)
```

### è¾“å‡ºæ ¼å¼

#### 1. Generated Report (generated_ids)
```python
Shape: [B, L_gen]
dtype: torch.int64
# ä½¿ç”¨ tokenizer.decode() è§£ç ä¸ºæ–‡æœ¬
```

#### 2. Predicted Mask (pred_masks)
```python
Shape: [B, 1, D, H, W]
dtype: torch.float32
Range: Logits (training) or [0, 1] probabilities (inference)
# ä½¿ç”¨ torch.sigmoid() è½¬æ¢ä¸ºæ¦‚ç‡
# ä½¿ç”¨ (probs > 0.5) è½¬æ¢ä¸ºäºŒå€¼æ©ç 
```

#### 3. Correction Info (correction_info)
```python
{
    'num_iterations': int,           # å®é™…è¿­ä»£æ¬¡æ•°
    'final_score': float,            # æœ€ç»ˆä¸€è‡´æ€§åˆ†æ•° [0, 1]
    'history': List[Dict],           # æ¯æ¬¡è¿­ä»£çš„è¯¦ç»†ç»“æœ
    'improved': bool                 # æ˜¯å¦æ¯”åˆå§‹ç‰ˆæœ¬æ”¹è¿›
}
```

---

## âš™ï¸ é…ç½®å‚æ•°è¯¦è§£

### Med3DLISAConfig å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| **LLM åŸºç¡€é…ç½®** ||||
| `hidden_size` | int | 4096 | LLM éšè—å±‚ç»´åº¦ |
| `num_experts` | int | 8 | MoE ä¸“å®¶æ•°é‡ |
| `num_experts_per_tok` | int | 2 | æ¯ä¸ª token æ¿€æ´»çš„ä¸“å®¶æ•° |
| **Stage 1 é…ç½®** ||||
| `biobert_model` | str | 'dmis-lab/biobert-v1.1' | BioBERT æ¨¡å‹è·¯å¾„ |
| `biobert_freeze_layers` | int | 8 | å†»ç»“çš„ BERT å±‚æ•° |
| `latent_dim` | int | 512 | å¯¹é½åçš„æ½œåœ¨ç©ºé—´ç»´åº¦ |
| `alignment_temperature` | float | 0.07 | å¯¹æ¯”å­¦ä¹ æ¸©åº¦å‚æ•° |
| **Stage 2 é…ç½®** ||||
| `rag_top_k` | int | 3 | æ£€ç´¢çš„ top-k çŸ¥è¯†æ•° |
| `rag_knowledge_dim` | int | 512 | çŸ¥è¯†åº“åµŒå…¥ç»´åº¦ |
| `rag_num_entries` | int | 1000 | çŸ¥è¯†åº“æ¡ç›®æ•° |
| `rag_injection_position` | str | 'prepend' | ä¸Šä¸‹æ–‡æ³¨å…¥ä½ç½® |
| **Stage 4 é…ç½®** ||||
| `consistency_threshold` | float | 0.7 | ä¸€è‡´æ€§é˜ˆå€¼ï¼ˆè§¦å‘ä¿®æ­£ï¼‰ |
| `max_correction_iterations` | int | 3 | æœ€å¤§ä¿®æ­£è¿­ä»£æ¬¡æ•° |
| `consistency_embed_dim` | int | 512 | ä¸€è‡´æ€§æ£€æŸ¥åµŒå…¥ç»´åº¦ |
| **æŸå¤±æƒé‡** ||||
| `lambda_alignment` | float | 0.1 | å¯¹é½æŸå¤±æƒé‡ |
| `lambda_dice` | float | 1.0 | åˆ†å‰²æŸå¤±æƒé‡ |
| `lambda_matching` | float | 0.5 | åŒ¹é…æŸå¤±æƒé‡ |

---

## ğŸ¨ ä½¿ç”¨åœºæ™¯ç¤ºä¾‹

### åœºæ™¯ 1: è‚ºç»“èŠ‚åˆ†å‰² + æŠ¥å‘Šç”Ÿæˆ
```python
# 1. å‡†å¤‡æç¤º
prompt = "Please analyze this CT scan, segment any lung nodules, and generate a diagnostic report. <SEG>"
input_ids = tokenizer(prompt, return_tensors='pt')['input_ids']

# 2. å‡†å¤‡ä¸´åºŠå†å²ï¼ˆå¯é€‰ï¼‰
clinical_history = "Patient is a 65-year-old male with a history of smoking."
report_ids = biobert_tokenizer(clinical_history, return_tensors='pt')

# 3. æ¨ç†
generated_ids, pred_mask, info = model.generate_with_mask(
    input_ids=input_ids,
    images=ct_volume,
    clinical_reports=report_ids,
    enable_self_correction=True
)

# 4. åå¤„ç†
report = tokenizer.decode(generated_ids[0], skip_special_tokens=True)
binary_mask = (torch.sigmoid(pred_mask) > 0.5).cpu().numpy()

print(f"Report: {report}")
print(f"Segmentation shape: {binary_mask.shape}")
print(f"Refinement iterations: {info['num_iterations']}")
```

### åœºæ™¯ 2: å¤šå™¨å®˜åˆ†å‰²
```python
prompt = "Segment the liver, kidneys, and spleen in this abdominal CT. <SEG>"

# æ³¨æ„: éœ€è¦æ¨¡å‹æ”¯æŒå¤šç±»åˆ«åˆ†å‰²
# å½“å‰ç‰ˆæœ¬æ”¯æŒå•ç±»åˆ«ï¼Œå¤šç±»åˆ«éœ€è¦æ‰©å±• SAM decoder
```

### åœºæ™¯ 3: è´¨é‡æ§åˆ¶ï¼ˆæ— åˆ†å‰²ï¼Œä»…æŠ¥å‘Šï¼‰
```python
prompt = "Generate a quality assessment report for this CT scan."
# ä¸åŒ…å« <SEG> tokenï¼Œæ¨¡å‹åªç”Ÿæˆæ–‡æœ¬

generated_ids, _, _ = model.generate_with_mask(
    input_ids=input_ids,
    images=ct_volume,
    enable_self_correction=False  # æ— æ©ç æ—¶å…³é—­ä¿®æ­£
)
```

---

## ğŸ”§ è°ƒè¯•å’Œç›‘æ§

### å¯ç”¨è¯¦ç»†è¾“å‡º
```python
# 1. æŸ¥çœ‹æ‰€æœ‰æŸå¤±é¡¹
outputs = model(...)
for key, value in outputs.items():
    if 'loss' in key and value is not None:
        print(f"{key}: {value.item():.4f}")

# 2. æ£€æŸ¥è·¯ç”±è´Ÿè½½
if 'router_logits' in outputs:
    router_logits = outputs['router_logits']
    expert_usage = torch.argmax(router_logits, dim=-1)
    print(f"Expert usage distribution: {expert_usage.unique(return_counts=True)}")

# 3. ç›‘æ§è‡ªæˆ‘ä¿®æ­£
_, _, info = model.generate_with_mask(..., enable_self_correction=True)
for i, h in enumerate(info['history']):
    print(f"Iter {i}: score={h['consistency_score']:.3f}")
```

### å¯è§†åŒ–å¯¹é½çŸ©é˜µ
```python
from model.encoders.uni_alignment import UnifiedAlignmentModule

alignment = model.model.alignment_module
outputs = alignment(image_features, text_features, return_loss=True)

# ç›¸ä¼¼åº¦çŸ©é˜µ [B, B]
similarity = outputs['image_embeds'] @ outputs['text_embeds'].T
print(similarity)  # å¯¹è§’çº¿åº”è¯¥è¾ƒå¤§ï¼ˆæ­£æ ·æœ¬ï¼‰
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. æ··åˆç²¾åº¦è®­ç»ƒ
```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

with autocast():
    outputs = model(...)
    loss = outputs['loss']

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```

### 2. DeepSpeed ZeRO
```python
import deepspeed

model_engine, optimizer, _, _ = deepspeed.initialize(
    model=model,
    model_parameters=model.parameters(),
    config={
        "train_batch_size": 8,
        "gradient_accumulation_steps": 4,
        "zero_optimization": {
            "stage": 2
        }
    }
)
```

### 3. æ¢¯åº¦æ£€æŸ¥ç‚¹
```python
# åœ¨é…ç½®ä¸­å¯ç”¨
config = Med3DLISAConfig(
    gradient_checkpointing=True,  # éœ€è¦æ·»åŠ æ­¤å‚æ•°
    ...
)
```

---

## â“ å¸¸è§é—®é¢˜ (FAQ)

### Q1: å¦‚ä½•åªä½¿ç”¨éƒ¨åˆ† Stageï¼Ÿ
A: é€šè¿‡è®¾ç½®æŸå¤±æƒé‡ä¸º 0 æ¥ç¦ç”¨æŸä¸ª Stageï¼š
```python
config = Med3DLISAConfig(
    lambda_alignment=0.0,  # ç¦ç”¨ Stage 1 alignment loss
    lambda_matching=0.0    # ç¦ç”¨ Stage 4 matching loss
)
```

### Q2: å¦‚ä½•è°ƒæ•´è‡ªæˆ‘ä¿®æ­£çš„æ•æ„Ÿåº¦ï¼Ÿ
A: è°ƒæ•´ `consistency_threshold`ï¼š
- æ›´é«˜é˜ˆå€¼ (0.8-0.9): æ›´ä¸¥æ ¼ï¼Œæ›´å¤šä¿®æ­£è¿­ä»£
- æ›´ä½é˜ˆå€¼ (0.5-0.6): æ›´å®½æ¾ï¼Œæ›´å°‘ä¿®æ­£è¿­ä»£

### Q3: å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
A: 
1. å‡å° batch size
2. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
3. å¯ç”¨ gradient checkpointing
4. é™ä½å›¾åƒåˆ†è¾¨ç‡
5. ä½¿ç”¨ DeepSpeed ZeRO-3

### Q4: å¦‚ä½•åŠ é€Ÿæ¨ç†ï¼Ÿ
A:
1. å…³é—­ `enable_self_correction`
2. ä½¿ç”¨ `torch.no_grad()`
3. æ‰¹é‡æ¨ç†
4. æ¨¡å‹é‡åŒ– (FP16/INT8)

---

## ğŸ“š æ›´å¤šèµ„æº

- **å®Œæ•´æ–‡æ¡£**: [ARCHITECTURE_UPDATE.md](ARCHITECTURE_UPDATE.md)
- **æµ‹è¯•è„šæœ¬**: `test_full_integration.py`
- **è®­ç»ƒè„šæœ¬**: `train_net.py`
- **é…ç½®ç¤ºä¾‹**: `config/med3d_lisa_full.yaml`

---

**ç‰ˆæœ¬**: v2.0  
**æ›´æ–°**: 2026-01-07
