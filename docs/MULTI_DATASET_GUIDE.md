# å¤šæ•°æ®é›†ä¸åˆ†é˜¶æ®µè®­ç»ƒæŒ‡å—

## ğŸ“‹ æ¦‚è¿°

Med3D-MoE-Seg ç°åœ¨æ”¯æŒï¼š
1. **å¤šæ•°æ®é›†è®­ç»ƒ** - åœ¨åŒä¸€é˜¶æ®µæ··åˆä½¿ç”¨å¤šä¸ªæ•°æ®é›†
2. **åˆ†é˜¶æ®µè®­ç»ƒ** - ä¸åŒè®­ç»ƒé˜¶æ®µä½¿ç”¨ä¸åŒçš„æ•°æ®é›†
3. **çµæ´»é…ç½®** - é€šè¿‡ YAML é…ç½®æ–‡ä»¶è½»æ¾åˆ‡æ¢æ•°æ®é›†
4. **å¯æ‰©å±•æ¶æ„** - è½»æ¾æ·»åŠ æ–°çš„æ•°æ®é›†ç±»å‹

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### 1. åŸºç±»è®¾è®¡

æ‰€æœ‰æ•°æ®é›†éƒ½ç»§æ‰¿è‡ª `BaseMedicalDataset`:

```python
from data.base_dataset import BaseMedicalDataset, DatasetRegistry

@DatasetRegistry.register('your_dataset_name')
class YourDataset(BaseMedicalDataset):
    def __init__(self, data_source, **kwargs):
        super().__init__(data_source=data_source, **kwargs)
        # ä½ çš„åˆå§‹åŒ–ä»£ç 
    
    def __getitem__(self, idx):
        # è¿”å›æ ‡å‡†æ ¼å¼çš„æ•°æ®
        return {
            'image': image_tensor,  # [D, H, W] or [C, D, H, W]
            'mask': mask_tensor,    # [D, H, W]
            'text': text_string,    # æ–‡æœ¬æè¿°
            'prompt': prompt_string,# æ ¼å¼åŒ–çš„ prompt
            'metadata': {...}       # å…ƒæ•°æ®
        }
    
    def get_dataset_info(self):
        # è¿”å›æ•°æ®é›†ä¿¡æ¯
        return {
            'name': 'YourDataset',
            'num_samples': len(self),
            'modality': 'CT',
            'task': 'segmentation',
            ...
        }
```

### 2. æ•°æ®é›†æ³¨å†Œæœºåˆ¶

ä½¿ç”¨ `@DatasetRegistry.register()` è£…é¥°å™¨æ³¨å†Œæ•°æ®é›†ï¼š

```python
# data/your_dataset.py
from data.base_dataset import BaseMedicalDataset, DatasetRegistry

@DatasetRegistry.register('your_dataset')
class YourDataset(BaseMedicalDataset):
    ...

# ä½¿ç”¨æ—¶
dataset = DatasetRegistry.create_dataset(
    'your_dataset',
    data_source='path/to/data.json',
    **other_params
)
```

---

## ğŸ“š æ”¯æŒçš„æ•°æ®é›†

### å½“å‰å·²æ³¨å†Œçš„æ•°æ®é›†

| æ•°æ®é›†åç§° | æ³¨å†Œå | ä»»åŠ¡ | æ¨¡æ€ | çŠ¶æ€ |
|-----------|--------|------|------|------|
| LIDC-IDRI | `lidc` | è‚ºç»“èŠ‚åˆ†å‰² | CT | âœ… å·²å®ç° |
| LungCT | `lungct` | è‚ºéƒ¨åˆ†å‰² | CT | ğŸ”„ å¾…å®ç° |
| MSD Lung | `msd` | è‚ºéƒ¨åˆ†å‰² | CT | ğŸ”„ å¾…å®ç° |
| è‡ªå®šä¹‰ | `custom` | è‡ªå®šä¹‰ | è‡ªå®šä¹‰ | ğŸ“ æ¨¡æ¿å¯ç”¨ |

### æŸ¥çœ‹å·²æ³¨å†Œçš„æ•°æ®é›†

```python
from data.base_dataset import DatasetRegistry

# åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„æ•°æ®é›†
print(DatasetRegistry.list_datasets())
# è¾“å‡º: ['lidc', 'lungct', 'msd', ...]
```

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1: å•æ•°æ®é›†è®­ç»ƒï¼ˆæœ€ç®€å•ï¼‰

é€‚ç”¨äºï¼šåˆæ­¥å®éªŒã€å•ä»»åŠ¡è®­ç»ƒ

**é…ç½®æ–‡ä»¶** (`config/single_dataset.yaml`):
```yaml
simple_mode:
  enabled: true
  dataset: "lidc"
  train_json: "data_splits/lidc/train.json"
  val_json: "data_splits/lidc/val.json"
  test_json: "data_splits/lidc/test.json"
  data_root: "processed_lidc_data"
  image_size: [128, 128, 128]
```

**è®­ç»ƒå‘½ä»¤**:
```bash
python train_net.py --config_file config/single_dataset.yaml
```

---

### åœºæ™¯ 2: å¤šæ•°æ®é›†æ··åˆè®­ç»ƒ

é€‚ç”¨äºï¼šå¢åŠ æ•°æ®å¤šæ ·æ€§ã€æå‡æ³›åŒ–èƒ½åŠ›

**é…ç½®æ–‡ä»¶** (`config/mixed_datasets.yaml`):
```yaml
training_stages:
  stage_full:
    enabled: true
    datasets: ["lidc", "lungct", "msd"]  # æ··åˆå¤šä¸ªæ•°æ®é›†
    
    # ä¸ºæ¯ä¸ªæ•°æ®é›†é…ç½®æ•°æ®æº
    lidc_config:
      train_source: "data_splits/lidc/train.json"
      val_source: "data_splits/lidc/val.json"
      dataset_params:
        data_root: "processed_lidc_data"
        image_size: [128, 128, 128]
    
    lungct_config:
      train_source: "data_splits/lungct/train.json"
      val_source: "data_splits/lungct/val.json"
      dataset_params:
        data_root: "processed_lungct_data"
        image_size: [128, 128, 128]
    
    msd_config:
      train_source: "data_splits/msd/train.json"
      dataset_params:
        data_root: "MSD_Lung_data"
        image_size: [128, 128, 128]
```

**è®­ç»ƒå‘½ä»¤**:
```bash
python train_net.py \
    --config_file config/mixed_datasets.yaml \
    --stage_name stage_full
```

---

### åœºæ™¯ 3: åˆ†é˜¶æ®µæ¸è¿›è®­ç»ƒ

é€‚ç”¨äºï¼šå¤æ‚æ¨¡å‹è®­ç»ƒã€é€æ­¥æå‡èƒ½åŠ›

**é…ç½®æ–‡ä»¶** (`config/multi_dataset_stages.yaml`):
```yaml
training_stages:
  # é˜¶æ®µ 1: ä½¿ç”¨ LIDC è¿›è¡Œå¯¹é½è®­ç»ƒ
  stage1_alignment:
    enabled: true
    dataset: "lidc"
    train_source: "data_splits/lidc/train.json"
    training:
      num_epochs: 20
      loss_weights:
        alignment_loss: 1.0
        seg_loss: 0.0
  
  # é˜¶æ®µ 2: æ··åˆ LIDC å’Œ LungCT è®­ç»ƒ RAG
  stage2_rag:
    enabled: true
    datasets: ["lidc", "lungct"]
    training:
      num_epochs: 30
      loss_weights:
        rag_retrieval_loss: 1.0
  
  # é˜¶æ®µ 3: ä½¿ç”¨ MSD å¤§æ•°æ®é›†å¾®è°ƒ LLM
  stage3_llm:
    enabled: true
    dataset: "msd"
    training:
      num_epochs: 40
      loss_weights:
        llm_loss: 1.0
  
  # é˜¶æ®µ 4: æ··åˆæ‰€æœ‰æ•°æ®é›†ç«¯åˆ°ç«¯è®­ç»ƒ
  stage4_full:
    enabled: true
    datasets: ["lidc", "lungct", "msd"]
    training:
      num_epochs: 50
      loss_weights:
        seg_loss: 1.0
        llm_loss: 0.5
        alignment_loss: 0.1
```

**è®­ç»ƒå‘½ä»¤**:
```bash
# é˜¶æ®µ 1
python train_net.py \
    --config_file config/multi_dataset_stages.yaml \
    --stage_name stage1_alignment \
    --output_dir outputs/stage1

# é˜¶æ®µ 2ï¼ˆåŠ è½½é˜¶æ®µ 1 çš„æƒé‡ï¼‰
python train_net.py \
    --config_file config/multi_dataset_stages.yaml \
    --stage_name stage2_rag \
    --output_dir outputs/stage2 \
    --resume_from outputs/stage1/checkpoint-best

# é˜¶æ®µ 3
python train_net.py \
    --config_file config/multi_dataset_stages.yaml \
    --stage_name stage3_llm \
    --output_dir outputs/stage3 \
    --resume_from outputs/stage2/checkpoint-best

# é˜¶æ®µ 4
python train_net.py \
    --config_file config/multi_dataset_stages.yaml \
    --stage_name stage4_full \
    --output_dir outputs/stage4 \
    --resume_from outputs/stage3/checkpoint-best
```

---

## ğŸ”§ æ·»åŠ æ–°æ•°æ®é›†

### æ­¥éª¤ 1: åˆ›å»ºæ•°æ®é›†ç±»

```python
# data/your_dataset.py
"""
Your Custom Dataset
"""

import torch
from pathlib import Path
from typing import Dict, List, Tuple
from .base_dataset import BaseMedicalDataset, DatasetRegistry


@DatasetRegistry.register('your_dataset')
class YourDataset(BaseMedicalDataset):
    """
    ä½ çš„è‡ªå®šä¹‰æ•°æ®é›†æè¿°
    """
    
    def __init__(self,
                 data_source: str,
                 data_root: str = ".",
                 image_size: Tuple[int, int, int] = (128, 128, 128),
                 normalize: bool = True,
                 augmentation: bool = False,
                 **kwargs):
        super().__init__(
            data_source=data_source,
            image_size=image_size,
            normalize=normalize,
            augmentation=augmentation
        )
        
        self.data_root = Path(data_root)
        
        # åŠ è½½ä½ çš„æ•°æ®åˆ—è¡¨
        self.data_list = self.load_data_list(data_source)
        
        print(f"Loaded {len(self.data_list)} samples from YourDataset")
    
    def load_data_list(self, data_source):
        """åŠ è½½æ•°æ®åˆ—è¡¨"""
        import json
        with open(data_source, 'r') as f:
            return json.load(f)
    
    def __len__(self):
        return len(self.data_list)
    
    def __getitem__(self, idx):
        item = self.data_list[idx]
        
        # åŠ è½½å›¾åƒå’Œ mask
        image = self.load_image(item['image_path'])
        mask = self.load_mask(item['mask_path'])
        
        # å½’ä¸€åŒ–
        if self.normalize:
            image = self.normalize_image(image)
        
        # å¢å¼º
        if self.augmentation:
            image, mask = self.apply_augmentation(image, mask)
        
        # è½¬æ¢ä¸º tensor
        image = torch.from_numpy(image).float()
        mask = torch.from_numpy(mask).long()
        
        return {
            'image': image,
            'mask': mask,
            'text': item.get('text', ''),
            'prompt': self.build_prompt(item),
            'metadata': item.get('metadata', {})
        }
    
    def get_dataset_info(self):
        return {
            'name': 'YourDataset',
            'num_samples': len(self),
            'modality': 'CT',  # æˆ– 'MRI', 'X-ray', etc.
            'task': 'segmentation',
            'classes': ['background', 'foreground'],
            'image_size': self.image_size,
        }
    
    @staticmethod
    def collate_fn(batch):
        """Collate function"""
        images = torch.stack([item['image'] for item in batch])
        masks = torch.stack([item['mask'] for item in batch])
        texts = [item['text'] for item in batch]
        prompts = [item['prompt'] for item in batch]
        metadata = [item['metadata'] for item in batch]
        
        return {
            'images': images,
            'masks': masks,
            'texts': texts,
            'prompts': prompts,
            'metadata': metadata,
        }
    
    def load_image(self, path):
        """å®ç°ä½ çš„å›¾åƒåŠ è½½é€»è¾‘"""
        pass
    
    def load_mask(self, path):
        """å®ç°ä½ çš„ mask åŠ è½½é€»è¾‘"""
        pass
    
    def build_prompt(self, item):
        """æ„å»º prompt"""
        return f"USER: <image>\nSegment the target in this image.\nASSISTANT:"
```

### æ­¥éª¤ 2: å¯¼å…¥åˆ° builder

```python
# data/builder.py
from .your_dataset import YourDataset  # è‡ªåŠ¨æ³¨å†Œ
```

### æ­¥éª¤ 3: åœ¨é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨

```yaml
training_stages:
  stage_custom:
    enabled: true
    dataset: "your_dataset"  # ä½¿ç”¨æ³¨å†Œå
    train_source: "path/to/your/train.json"
    val_source: "path/to/your/val.json"
    dataset_params:
      data_root: "path/to/data"
      image_size: [128, 128, 128]
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. æ•°æ®é›†é€‰æ‹©ç­–ç•¥

| è®­ç»ƒé˜¶æ®µ | æ¨èæ•°æ®é›† | åŸå›  |
|---------|-----------|------|
| Stage 1 (Alignment) | å°è§„æ¨¡æ ‡æ³¨æ•°æ®é›† | å¿«é€ŸéªŒè¯å¯¹é½æ•ˆæœ |
| Stage 2 (RAG) | å¤šé¢†åŸŸæ··åˆæ•°æ® | æå‡æ£€ç´¢å¤šæ ·æ€§ |
| Stage 3 (LLM) | å¤§è§„æ¨¡æ•°æ®é›† | å……åˆ†è®­ç»ƒè¯­è¨€èƒ½åŠ› |
| Stage 4 (Full) | æ‰€æœ‰å¯ç”¨æ•°æ®é›† | æœ€å¤§åŒ–æ³›åŒ–èƒ½åŠ› |

### 2. æ•°æ®æ ¼å¼ç»Ÿä¸€

ç¡®ä¿æ‰€æœ‰æ•°æ®é›†çš„ JSON æ–‡ä»¶æ ¼å¼ä¸€è‡´ï¼š

```json
[
  {
    "id": "sample_001",
    "image_path": "relative/path/to/image.nii.gz",
    "mask_path": "relative/path/to/mask.nii.gz",
    "text": "Optional text description",
    "metadata": {
      "patient_id": "P001",
      "modality": "CT",
      "additional_info": "..."
    }
  },
  ...
]
```

### 3. æ•°æ®å¢å¼ºç­–ç•¥

- **è®­ç»ƒé›†**: å¯ç”¨å¢å¼ºï¼ˆç¿»è½¬ã€æ—‹è½¬ã€ç¼©æ”¾ï¼‰
- **éªŒè¯é›†**: ç¦ç”¨å¢å¼º
- **æµ‹è¯•é›†**: ç¦ç”¨å¢å¼º

### 4. æ‰¹æ¬¡å¤§å°è°ƒæ•´

æ··åˆå¤šä¸ªæ•°æ®é›†æ—¶ï¼Œè€ƒè™‘è°ƒæ•´æ‰¹æ¬¡å¤§å°ï¼š

```yaml
training:
  per_device_train_batch_size: 2  # å¤šæ•°æ®é›†æ—¶å‡å°
  gradient_accumulation_steps: 8  # å¢åŠ ç´¯ç§¯æ­¥æ•°ä¿æŒæœ‰æ•ˆ batch size
```

---

## ğŸ§ª æµ‹è¯•ä¸éªŒè¯

### æµ‹è¯•æ•°æ®é›†åŠ è½½

```python
from data.base_dataset import DatasetRegistry

# åˆ›å»ºæ•°æ®é›†
dataset = DatasetRegistry.create_dataset(
    'lidc',
    data_source='data_splits/lidc/train.json',
    data_root='processed_lidc_data',
    image_size=(128, 128, 128)
)

# æµ‹è¯•åŠ è½½
print(f"Dataset size: {len(dataset)}")
print(f"Dataset info: {dataset.get_dataset_info()}")

# åŠ è½½ä¸€ä¸ªæ ·æœ¬
sample = dataset[0]
print(f"Sample keys: {sample.keys()}")
print(f"Image shape: {sample['image'].shape}")
print(f"Mask shape: {sample['mask'].shape}")
```

### æµ‹è¯•å¤šæ•°æ®é›†æ··åˆ

```python
from data.base_dataset import create_multi_stage_datasets
import yaml

# åŠ è½½é…ç½®
with open('config/multi_dataset_stages.yaml') as f:
    config = yaml.safe_load(f)

# åˆ›å»ºé˜¶æ®µæ•°æ®é›†
stage_datasets = create_multi_stage_datasets(config['training_stages'])

# æ£€æŸ¥å„é˜¶æ®µæ•°æ®é›†
for stage_name, datasets in stage_datasets.items():
    print(f"\n{stage_name}:")
    print(f"  Train: {len(datasets['train'])} samples")
    print(f"  Val: {len(datasets['val']) if datasets['val'] else 'None'} samples")
```

---

## ğŸ“– å®Œæ•´ç¤ºä¾‹

### ç¤ºä¾‹ï¼šæ··åˆ 3 ä¸ªæ•°æ®é›†è®­ç»ƒ

```yaml
# config/my_training.yaml
training_stages:
  stage_full:
    enabled: true
    datasets: ["lidc", "lungct", "msd"]
    
    lidc_config:
      train_source: "data/lidc/train.json"
      val_source: "data/lidc/val.json"
      dataset_params:
        data_root: "datasets/lidc"
        image_size: [128, 128, 128]
        normalize: true
        augmentation: true
    
    lungct_config:
      train_source: "data/lungct/train.json"
      val_source: "data/lungct/val.json"
      dataset_params:
        data_root: "datasets/lungct"
        image_size: [128, 128, 128]
    
    msd_config:
      train_source: "data/msd/train.json"
      dataset_params:
        data_root: "datasets/msd"
        image_size: [128, 128, 128]
    
    training:
      num_epochs: 50
      batch_size: 2
      learning_rate: 2.0e-5
```

```bash
# è®­ç»ƒå‘½ä»¤
python train_net.py \
    --config_file config/my_training.yaml \
    --stage_name stage_full \
    --output_dir outputs/mixed_training
```

---

## ğŸ†˜ å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•æŸ¥çœ‹å·²æ³¨å†Œçš„æ•°æ®é›†ï¼Ÿ

```python
from data.base_dataset import DatasetRegistry
print(DatasetRegistry.list_datasets())
```

### Q2: ä¸åŒæ•°æ®é›†çš„å›¾åƒå°ºå¯¸ä¸åŒæ€ä¹ˆåŠï¼Ÿ

æ‰€æœ‰æ•°æ®é›†éƒ½ä¼š resize åˆ°é…ç½®çš„ `image_size`ï¼Œç¡®ä¿ç»Ÿä¸€ã€‚

### Q3: å¦‚ä½•æ·»åŠ è‡ªå·±çš„æ•°æ®é›†ï¼Ÿ

å‚è€ƒ"æ·»åŠ æ–°æ•°æ®é›†"ç« èŠ‚ï¼Œç»§æ‰¿ `BaseMedicalDataset` å¹¶æ³¨å†Œã€‚

### Q4: å¯ä»¥åœ¨åŒä¸€é˜¶æ®µä½¿ç”¨ä¸åŒçš„æŸå¤±æƒé‡å—ï¼Ÿ

å¯ä»¥ï¼Œåœ¨é…ç½®æ–‡ä»¶çš„ `training.loss_weights` ä¸­è®¾ç½®ã€‚

### Q5: å¦‚ä½•åªä½¿ç”¨æŸä¸ªæ•°æ®é›†çš„å­é›†ï¼Ÿ

åœ¨æ•°æ®åˆ’åˆ† JSON æ–‡ä»¶ä¸­ç­›é€‰æ ·æœ¬å³å¯ã€‚

---

**å‚è€ƒæ–‡æ¡£**:
- [data/base_dataset.py](data/base_dataset.py) - åŸºç±»å®šä¹‰
- [data/lidc_dataset.py](data/lidc_dataset.py) - LIDC å®ç°ç¤ºä¾‹
- [config/multi_dataset_stages.yaml](config/multi_dataset_stages.yaml) - é…ç½®ç¤ºä¾‹
